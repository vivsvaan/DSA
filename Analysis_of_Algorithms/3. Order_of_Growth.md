# Order of Growth

- Order of growth refers to how the runtime or space requirement of an algorithm increases as the size of the input (denoted as n) grows.
- It is an important concept in asymptotic analysis, used to classify algorithms based on their efficiency.

## Why is it important?
- It helps compare algorithms by focusing on their most significant growth patterns.
- It is crucial for predicting the scalability and performance of algorithms as input sizes increase.

## Steps
- If we have multiple Algorithms/Solutions, we find time taken by all the solutions.
- We write the Polynomial and then we see the Order of Growth of every time equation of each Algorithm/Solution.
- The one having the least Order of Growth is said to be Efficient Algorithm.

## Proof of Concept
A function **_f(n)_** is said to be growing faster than a function **_g(n)_** if
#### $$\lim_{x\to\infty} \frac{g(n)}{f(n)} = 0 \qquad or \qquad \lim_{x\to\infty} \frac{f(n)}{g(n)} = \infty$$
f(n) and g(n) represent time taken, n $\ge$ 0 and f(n), g(n) $\ge$ 0